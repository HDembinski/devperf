{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6e60243",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import timedelta\n",
    "\n",
    "df = pl.read_csv(\"Tf-Schichtbesetzung PoC.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c883c586",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df), (df[\"State\"] == \"New\").sum(), (df[\"State\"] == \"Closed\").sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21680efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_datetime(col: str) -> pl.Expr:\n",
    "    return pl.col(col).str.strptime(pl.Datetime, r\"%d.%m.%Y %H:%M:%S\", strict=False)\n",
    "\n",
    "df_dt = (\n",
    "    df.with_columns([\n",
    "        to_datetime(\"Activated Date\"),\n",
    "        to_datetime(\"Closed Date\"),\n",
    "    ])\n",
    "    .drop_nulls([\"Activated Date\", \"Closed Date\"])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca76c3a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "\n",
    "\n",
    "def assign_offsets(intervals: list[tuple[dt.datetime, dt.datetime]]) -> list[int]:\n",
    "    \"\"\"\n",
    "    Assigns a vertical offset level for each (start, end) interval.\n",
    "    Overlapping intervals receive different levels.\n",
    "    \"\"\"\n",
    "    levels: list[list[tuple[dt.datetime, dt.datetime]]] = []\n",
    "\n",
    "    for start, end in intervals:\n",
    "        placed = False\n",
    "        for level in levels:\n",
    "            # Check if last interval in level overlaps\n",
    "            last_start, last_end = level[-1]\n",
    "            if end >= last_start and start <= last_end:\n",
    "                # overlap → try next level\n",
    "                continue\n",
    "            else:\n",
    "                # no overlap → put here\n",
    "                level.append((start, end))\n",
    "                placed = True\n",
    "                break\n",
    "\n",
    "        if not placed:\n",
    "            # create new level\n",
    "            levels.append([(start, end)])\n",
    "\n",
    "    # Map each interval to its level index\n",
    "    out = []\n",
    "    for i, (start, end) in enumerate(intervals):\n",
    "        for lvl_idx, lvl in enumerate(levels):\n",
    "            if (start, end) in lvl:\n",
    "                out.append(lvl_idx)\n",
    "                break\n",
    "    return out\n",
    "\n",
    "\n",
    "def plot_ticket_timeline(df: pl.DataFrame) -> None:\n",
    "    # Parse dates\n",
    "    df = df.with_columns([\n",
    "        to_datetime(\"Activated Date\"),\n",
    "        to_datetime(\"Closed Date\"),\n",
    "        pl.col(\"Assigned To\").str.replace(r\"<.*>\", \"\").str.strip_chars(),\n",
    "    ])\n",
    "\n",
    "    # Keep only tickets with valid date ranges\n",
    "    df = df.drop_nulls([\"Activated Date\", \"Closed Date\"])\n",
    "\n",
    "    processing_time_expr = pl.col(\"Closed Date\") - pl.col(\"Activated Date\")\n",
    "\n",
    "    # Drop very long tickets, which are architectual or enabling tickets\n",
    "    df = df.filter(processing_time_expr < timedelta(days=30))\n",
    "\n",
    "    devs:list[str] = df[\"Assigned To\"].unique().to_list()\n",
    "    dev_ypos = {dev: i for i, dev in enumerate(devs)}\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(14, 0.7 * len(devs)))\n",
    "\n",
    "    for icol, dev in enumerate(devs):\n",
    "        ddf = df.filter(pl.col(\"Assigned To\") == dev).sort(\"Activated Date\")\n",
    "\n",
    "        # extract intervals\n",
    "        intervals = [\n",
    "            (row[\"Activated Date\"], row[\"Closed Date\"])\n",
    "            for row in ddf.iter_rows(named=True)\n",
    "        ]\n",
    "\n",
    "        # assign stacking offsets\n",
    "        offsets = assign_offsets(intervals)\n",
    "\n",
    "        # draw\n",
    "        base_y = dev_ypos[dev] * 5  # spacing between developers\n",
    "\n",
    "        first = True\n",
    "        for (start, end), off in zip(intervals, offsets):\n",
    "            ax.hlines(\n",
    "                y=base_y + off,\n",
    "                xmin=start,\n",
    "                xmax=end,\n",
    "                linewidth=3,\n",
    "                color=f\"C{icol}\",\n",
    "                label=dev if first else None # type:ignore\n",
    "            )\n",
    "            first = None\n",
    "\n",
    "    fig.legend(ncol=3)\n",
    "\n",
    "    ax.set_yticks([])\n",
    "    ax.set_xlabel(\"Date\")\n",
    "    ax.set_title(\"Ticket Timelines\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Usage:\n",
    "plot_ticket_timeline(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b0c828b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, time, date\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "\n",
    "SECONDS_PER_DAY = 24 * 3600\n",
    "\n",
    "def _is_weekday(d: date) -> bool:\n",
    "    return d.weekday() < 5  # Mon=0 ... Sun=6\n",
    "\n",
    "def _day_bounds(dt: datetime) -> tuple[datetime, datetime]:\n",
    "    start = datetime.combine(dt.date(), time.min)\n",
    "    end = start + timedelta(days=1)\n",
    "    return start, end\n",
    "\n",
    "def working_seconds_between(start: datetime, end: datetime) -> float:\n",
    "    \"\"\"\n",
    "    Exact working seconds between two datetimes, counting only Mon-Fri.\n",
    "    - Counts full middle business days with numpy.busday_count\n",
    "    - Adds partial time on the first and last business day\n",
    "    \"\"\"\n",
    "    if start >= end:\n",
    "        return 0.0\n",
    "\n",
    "    # Full business days strictly between start.date() and end.date()\n",
    "    start_next_midnight = datetime.combine(start.date() + timedelta(days=1), time.min)\n",
    "    end_midnight = datetime.combine(end.date(), time.min)\n",
    "    full_days = int(np.busday_count(start_next_midnight.date(), end_midnight.date()))\n",
    "    seconds = full_days * SECONDS_PER_DAY\n",
    "\n",
    "    # Partial time on the start day (if weekday)\n",
    "    if _is_weekday(start.date()):\n",
    "        _, start_day_end = _day_bounds(start)\n",
    "        seconds += (min(end, start_day_end) - start).total_seconds()\n",
    "\n",
    "    # Partial time on the end day (if different day and weekday)\n",
    "    if end.date() != start.date() and _is_weekday(end.date()):\n",
    "        end_day_start, _ = _day_bounds(end)\n",
    "        seconds += (end - max(start, end_day_start)).total_seconds()\n",
    "\n",
    "    # Clamp to the raw total to avoid floating rounding oddities\n",
    "    return max(0.0, min(seconds, (end - start).total_seconds()))\n",
    "\n",
    "# 2) Compute working seconds and working days\n",
    "df_work = (\n",
    "    df_dt.with_columns(\n",
    "        pl.struct([\"Activated Date\", \"Closed Date\"])\n",
    "          .map_elements(\n",
    "              lambda s: working_seconds_between(s[\"Activated Date\"], s[\"Closed Date\"]),\n",
    "              return_dtype=pl.Float64,\n",
    "          )\n",
    "          .alias(\"working_seconds\")\n",
    "    )\n",
    "    .with_columns((pl.col(\"working_seconds\") / SECONDS_PER_DAY).alias(\"working_days\"))\n",
    ")\n",
    "\n",
    "# 3) Median & mean (working days)\n",
    "median_days = df_work.select(pl.col(\"working_days\").median()).item()\n",
    "mean_days   = df_work.select(pl.col(\"working_days\").mean()).item()\n",
    "\n",
    "print(f\"median processing time (working days): {median_days:.1f}\")\n",
    "print(f\"mean processing time   (working days): {mean_days:.1f}\")\n",
    "\n",
    "# per-developer summary\n",
    "df_per_dev = (\n",
    "    df_work\n",
    "    .with_columns(\n",
    "        pl.col(\"Assigned To\").str.replace(r\"<.*>\", \"\").str.strip_chars().alias(\"Developer\")\n",
    "    )\n",
    "    .group_by(\"Developer\")\n",
    "    .agg(\n",
    "        pl.col(\"working_days\").median().alias(\"median_days\"),\n",
    "        pl.col(\"working_days\").mean().alias(\"mean_days\"),\n",
    "        pl.len().alias(\"n_tickets\"),\n",
    "    )\n",
    "    .sort(\"mean_days\")\n",
    ")\n",
    "print(df_per_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dbc1eeb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea452d68",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "devperf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
